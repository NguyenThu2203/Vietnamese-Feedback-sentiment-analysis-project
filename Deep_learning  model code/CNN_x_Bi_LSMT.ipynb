{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aankvbft7GeB",
        "outputId": "b846251e-f9d2-49ca-ee65-e0dc71389cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyvi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfPixFLu9wMt",
        "outputId": "f03125e5-9dd7-4461-e396-c90a398c6806"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as py\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, LSTM, GRU, Input, GlobalMaxPooling1D, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras. preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pyvi import ViTokenizer\n",
        "from pyvi import ViUtils"
      ],
      "metadata": {
        "id": "0_Ub6oBA92V3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd. read_excel(\"/content/drive/MyDrive/Colab Notebooks/DATA/Datacomment.xlsx\")\n",
        "data.head(10)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhkKPR-x97D0",
        "outputId": "53531d89-dbda-4662-e0b5-88bf8dff9afd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1649, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_data = pd.DataFrame({'input':data['Comment'], 'label':data['Label']})\n",
        "sentiment_data = sentiment_data.dropna()\n",
        "sentiment_data = sentiment_data.reset_index(drop=True)\n",
        "sentiment_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XLLM57ql9-Lt",
        "outputId": "664bda14-48cc-4aba-8951-e5901a025afb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               input label\n",
              "0  Không nên mua chuột cua Logitech , vì dùng nó ...   Pos\n",
              "1  Nói thiệt là mình thì thì chuột nào mình cũng ...   Neg\n",
              "2                Xai chuot so nhat bi double click .   Neu\n",
              "3  Cơ bản là thiết kế ôm chuột chưa đã Như hiện g...   Pos\n",
              "4  Đang dùng mx 1 . Cũng ngon nhưng chưa đầy năm ...   Neg"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48bf7cd6-8352-4a11-8be5-a9a22a474c72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Không nên mua chuột cua Logitech , vì dùng nó ...</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nói thiệt là mình thì thì chuột nào mình cũng ...</td>\n",
              "      <td>Neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Xai chuot so nhat bi double click .</td>\n",
              "      <td>Neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cơ bản là thiết kế ôm chuột chưa đã Như hiện g...</td>\n",
              "      <td>Pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Đang dùng mx 1 . Cũng ngon nhưng chưa đầy năm ...</td>\n",
              "      <td>Neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48bf7cd6-8352-4a11-8be5-a9a22a474c72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48bf7cd6-8352-4a11-8be5-a9a22a474c72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48bf7cd6-8352-4a11-8be5-a9a22a474c72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf0db222-2a2a-4be1-90fc-f94ebbd7e263\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf0db222-2a2a-4be1-90fc-f94ebbd7e263')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf0db222-2a2a-4be1-90fc-f94ebbd7e263 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sentiment_data",
              "summary": "{\n  \"name\": \"sentiment_data\",\n  \"rows\": 1649,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1617,\n        \"samples\": [\n          \"\\ufeffB\\u00e1c cho m\\u00ecnh h\\u1ecfi , m\\u00ecnh s\\u00e0i aw 42 nh\\u00f4m \\u0111en , s\\u00e0i dc 1 th\\u00e1ng r\\u1ed3i , nh\\u01b0ng up os 2 dc 2 tu\\u1ea7n th\\u00ec b\\u1ecb 1 l\\u1ed7i \\u0111\\u00fang 2 l\\u1ea7n . L\\u1ed7i l\\u00e0 , b\\u1ecb 2 l\\u1ea7n , t\\u1ee5 nhi\\u00ean khi m\\u00ecnh d\\u00f9ng force t\\u00f5uh , th\\u00ec c\\u00e1i taptic n\\u00f3 rung l\\u00ean k\\u00e8m 1 ti\\u1ebfng t\\u1eb9t t\\u1eb9t , nh\\u1ea5n b\\u1ea5t c\\u1ee9 c\\u00e1i g\\u00ec c\\u00f3 taptic l\\u00e0 nghe \\u00e2m thanh \\u0111\\u00f3 , re\\u00eat l\\u1ea1i th\\u00ec ko b\\u1ecb n\\u1eefa , cho m\\u00ecnh h\\u1ecfi c\\u00f3 b\\u00e1c n\\u00e0o b\\u1ecb v\\u1eady ko\",\n          \"\\ufeffM\\u00ecnh r\\u1ea5t th\\u00edch windown phone nh\\u01b0ng m\\u00ecnh kh\\u00f4ng mua b\\u1edfi v\\u1ec9 kh\\u00f4ng c\\u00f3 game m\\u00ecnh \\u0111ang ch\\u01a1i . \\u0110\\u00f3 l\\u00e0 \\u0111i\\u1ec1u r\\u1ea5t b\\u1ea5t l\\u1ee3i c\\u1ee7a WP\",\n          \"C\\u00e1p m\\u1ea1ng n\\u00e0y c\\u00f3 t\\u1ed1c \\u0111\\u1ed9 Gigabit.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Pos\",\n          \"Neg\",\n          \"Neu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#xóa dữ liệu trùng lặp\n",
        "sentiment_data.drop_duplicates()\n",
        "sentiment_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7k1BzR0-Am1",
        "outputId": "29e9bf47-2f4c-487a-ae92-9f5761770401"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1649, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = sentiment_data['input'].values\n",
        "input_label = sentiment_data['label'].values\n",
        "\n",
        "label_dict = {'Neg':0,'Pos':1, 'Neu': 2}\n",
        "\n",
        "input_pre = []\n",
        "label_with_accent = []\n",
        "for idx, dt in enumerate(input_data):\n",
        "  #input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(dt))\n",
        "  input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(str(dt)))\n",
        "  input_text_pre = \" \".join(input_text_pre)\n",
        "  input_text_pre_no_accent = str(ViUtils.remove_accents(input_text_pre).decode(\"utf-8\"))\n",
        "  input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
        "  input_text_pre_no_accent = ViTokenizer.tokenize(input_text_pre_no_accent)\n",
        "  input_pre.append(input_text_pre_accent)\n",
        "  input_pre.append(input_text_pre_no_accent)\n",
        "  label_with_accent.append(input_label[idx])\n",
        "  label_with_accent.append(input_label[idx])"
      ],
      "metadata": {
        "id": "ZrDCb5Xx-EW4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_count = len(data[data['Label'] == 'Neg'])\n",
        "print(\"Số lượng nhãn Negative là:\", negative_count)\n",
        "\n",
        "positive_count = len(data[data['Label'] == 'Pos'])\n",
        "print(\"Số lượng nhãn Positive là:\", positive_count)\n",
        "\n",
        "neutral_count = len(data[data['Label'] == 'Neu'])\n",
        "print(\"Số lượng nhãn Neutral là:\", neutral_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq0YFgMQ-kW-",
        "outputId": "2b1e1976-e956-41d2-91a9-0a7706ba1c4e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng nhãn Negative là: 593\n",
            "Số lượng nhãn Positive là: 552\n",
            "Số lượng nhãn Neutral là: 504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuyển đổi tokenizer bộ dữ liệu và lưu vào file\n",
        "label_idx = [label_dict[i] for i in label_with_accent]\n",
        "label_tf = tf.keras.utils.to_categorical(label_idx, num_classes=3, dtype='float32')\n",
        "\n",
        "# khởi tạo một đối tượng tokenizer_data từ lớp Tokenizer trong Keras để mã hóa\n",
        "# và chuyển đổi dữ liệu văn bản thành chuỗi số nguyên.\n",
        "tokenizer_data = Tokenizer(oov_token='<OOV>', filters = '', split = ' ')\n",
        "\n",
        "# sử dụng phương thức fit_on_texts() của tokenizer_data để thực hiện mã hóa\n",
        "# từ vựng và xây dựng từ điển từ dữ liệu input_pre. Điều này giúp xác định\n",
        "# các từ duy nhất và gán một số nguyên duy nhất cho mỗi từ.\n",
        "tokenizer_data.fit_on_texts(input_pre)\n",
        "\n",
        "# sử dụng phương thức texts_to_sequences() của tokenizer_data để chuyển đổi\n",
        "# dữ liệu văn bản input_pre thành các chuỗi số nguyên tương ứng với từng\n",
        "# từ trong từ điển\n",
        "tokenizer_data_text = tokenizer_data.texts_to_sequences(input_pre)\n",
        "\n",
        "# sử dụng hàm pad_sequences() để đệm các chuỗi số nguyên trong\n",
        "# tokenizer_data_text thành cùng một độ dài (maxlen = 120).\n",
        "# Điều này đảm bảo rằng các chuỗi đầu vào có cùng kích thước\n",
        "vec_data = pad_sequences(tokenizer_data_text, padding='post', maxlen = 120)\n",
        "\n",
        "pickle.dump(tokenizer_data, open(\"tokenizer_data.pkl\", \"wb\"))\n",
        "# Lưu model tokenizer_data.pkl vào đường dẫn /content/drive/My Drive/CD\n",
        "with open(\"/content/drive/MyDrive/tokenizer_data.pkl\", \"wb\") as file:\n",
        "    pickle.dump(tokenizer_data, file)\n",
        "\n",
        "print(\"input data.shape\", vec_data.shape)\n",
        "data_vocab_size = len(tokenizer_data.word_index)+1\n",
        "print(\"data_vocab_size: \", data_vocab_size)\n",
        "\n",
        "# Chia tập dữ liệu thành 3 phần train, val, test\n",
        "X_train, X_val, y_train, y_val = train_test_split(vec_data, label_tf, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(vec_data, label_tf, test_size=0.1, random_state = 42)\n",
        "print(\"Training sample: \", len(X_train))\n",
        "print(\"Validation sample: \", len(X_val))\n",
        "print(\"Test sample: \", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeU7wrMc-mG7",
        "outputId": "3ce5d243-a72e-4384-ab34-aefd78dc94c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input data.shape (3298, 120)\n",
            "data_vocab_size:  5158\n",
            "Training sample:  2968\n",
            "Validation sample:  660\n",
            "Test sample:  330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Bidirectional, LSTM\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "88JFN9vT-n1f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model():\n",
        "  # khai báo ngưỡng dropout, đại diện cho tỷ lệ các đơn vị bị bỏ qua\n",
        "  # trong quá trình huấn luyện để tránh việc quá khớp (overfitting)\n",
        "  dropout_threshold = 0.3\n",
        "\n",
        "  # gán kích thước của từ điển từ dữ liệu cho biến input_dim\n",
        "  input_dim = data_vocab_size\n",
        "\n",
        "  # gán kích thước đầu ra của lớp nhúng (embedding) cho biến output_dim.\n",
        "  # Trong trường hợp này, các từ sẽ được biểu diễn bằng một vector 32 chiều.\n",
        "  output_dim = 32\n",
        "\n",
        "  # gán độ dài đầu vào cho biến input_length. đảm bảo rằng độ dài của các chuỗi\n",
        "  # đầu vào sẽ được đệm (padding) hoặc cắt (truncation) để có cùng kích thước\n",
        "  input_length = 120\n",
        "\n",
        "  # khởi tạo một đối tượng GlorotNormal từ module initializers trong\n",
        "  # thư viện Keras để sử dụng làm trình khởi tạo trọng số cho mạng nơ-ron.\n",
        "  initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "  # khai báo lớp đầu vào với kích thước đầu vào là input_length\n",
        "  input_layer = Input(shape=input_length)\n",
        "\n",
        "  # thực hiện lớp nhúng (embedding) ánh xạ các từ sang các vector dựa trên\n",
        "  # input_dim và output_dim. embeddings_initializer được sử dụng để khởi tạo\n",
        "  # ma trận trọng số của lớp nhúng\n",
        "  feature = Embedding(input_dim=input_dim, output_dim=output_dim,\n",
        "                      input_length=input_length,\n",
        "                      embeddings_initializer=\"GlorotNormal\")(input_layer)\n",
        "\n",
        "  # Sử dụng mạng nơ ron tích chập trích xuất các đặc trưng từ đầu vào đã nhúng.\n",
        "  # Các lớp này được sử dụng để tạo một đặc trưng từ ngữ cảnh và cấu trúc của câu\n",
        "  cnn_feature = Conv1D(filters=32, kernel_size=3, padding='same',\n",
        "                       activation='relu')(feature)\n",
        "  cnn_feature = MaxPooling1D()(cnn_feature)\n",
        "  cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n",
        "  cnn_feature = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(cnn_feature)\n",
        "  cnn_feature = MaxPooling1D()(cnn_feature)\n",
        "  cnn_feature = LayerNormalization()(cnn_feature)\n",
        "  cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n",
        "\n",
        "  # chuỗi các lớp LSTM hai chiều (Bidirectional LSTM) để trích xuất\n",
        "  # các đặc trưng từ các chuỗi đầu vào. Lớp này giúp mô hình có khả năng học\n",
        "  # được các phụ thuộc dài hạn trong dữ liệu chuỗi.\n",
        "  bi_lstm_feature = Bidirectional(LSTM(units=32, dropout=dropout_threshold,\n",
        "                                       return_sequences=True,\n",
        "                                       kernel_initializer=initializer),\n",
        "                                  merge_mode = 'concat')(feature)\n",
        "  bi_lstm_feature = MaxPooling1D()(bi_lstm_feature)\n",
        "\n",
        "  bi_lstm_feature = Bidirectional(LSTM(units=32, dropout=dropout_threshold,\n",
        "                                       return_sequences=True,\n",
        "                                       kernel_initializer=initializer),\n",
        "                                  merge_mode = 'concat')(bi_lstm_feature)\n",
        "  bi_lstm_feature = MaxPooling1D()(bi_lstm_feature)\n",
        "  bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n",
        "\n",
        "  # kết hợp hai tập đặc trưng từ các lớp tích chập và LSTM thành\n",
        "  # một tập đặc trưng duy nhất bằng cách kết hợp chúng theo chiều thứ hai.\n",
        "  combine_feature = tf.keras.layers.Concatenate()([cnn_feature, bi_lstm_feature])\n",
        "  combine_feature = GlobalMaxPooling1D()(combine_feature)\n",
        "  combine_feature = LayerNormalization()(combine_feature)\n",
        "\n",
        "  # chuỗi các lớp mạng nơ-ron tiếp theo để xử lý tập đặc trưng đã kết hợp.\n",
        "  # Các lớp này thực hiện các phép biến đổi phi tuyến để tạo ra dự đoán cuối cùng.\n",
        "  classifier = Dense(90, activation = 'relu')(combine_feature)\n",
        "  classifier = Dropout(0.3)(classifier)\n",
        "  classifier = Dense(70, activation = 'relu')(classifier)\n",
        "  classifier = Dropout(0.3)(classifier)\n",
        "  classifier = Dense(50, activation = 'relu')(classifier)\n",
        "  classifier = Dropout(0.3)(classifier)\n",
        "  classifier = Dense(30, activation = 'relu')(classifier)\n",
        "  classifier = Dropout(0.3)(classifier)\n",
        "  classifier = Dense(3, activation = 'softmax')(classifier)\n",
        "\n",
        "  model = tf.keras.Model(inputs = input_layer, outputs= classifier)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = generate_model()\n",
        "adam = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vhzDG8--qgT",
        "outputId": "070168cb-cb77-4f60-ea28-f25c6a4c4fc3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 120)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 120, 32)              165056    ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 120, 32)              3104      ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 60, 32)               0         ['conv1d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 60, 32)               0         ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 120, 64)              16640     ['embedding[0][0]']           \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 60, 32)               3104      ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPoolin  (None, 60, 64)               0         ['bidirectional[0][0]']       \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPoolin  (None, 30, 32)               0         ['conv1d_1[0][0]']            \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 60, 64)               24832     ['max_pooling1d_2[0][0]']     \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, 30, 32)               64        ['max_pooling1d_1[0][0]']     \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPoolin  (None, 30, 64)               0         ['bidirectional_1[0][0]']     \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 30, 32)               0         ['layer_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_1 (Lay  (None, 30, 64)               128       ['max_pooling1d_3[0][0]']     \n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 30, 96)               0         ['dropout_1[0][0]',           \n",
            "                                                                     'layer_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 96)                   0         ['concatenate[0][0]']         \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " layer_normalization_2 (Lay  (None, 96)                   192       ['global_max_pooling1d[0][0]']\n",
            " erNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 90)                   8730      ['layer_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 90)                   0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 70)                   6370      ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)         (None, 70)                   0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 50)                   3550      ['dropout_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)         (None, 50)                   0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 30)                   1530      ['dropout_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)         (None, 30)                   0         ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 3)                    93        ['dropout_5[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 233393 (911.69 KB)\n",
            "Trainable params: 233393 (911.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Huấn luyện mô hình máy học sử dụng mạng CNN-BiLSTM trên dữ liệu huấn luyện\n",
        "# và dữ liệu kiểm tra (validation)\n",
        "\n",
        "callback_model = tf.keras.callbacks.ModelCheckpoint('model_cnn_bilstm.h5', monitor='val_loss')\n",
        "history = model.fit(x = X_train, y = y_train, validation_data = (X_val, y_val), epochs = 50, batch_size = 128, callbacks=[callback_model])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-lCTFPi-s7e",
        "outputId": "8c52b14c-e105-4397-e093-d966b035c10d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 24s 500ms/step - loss: 1.1220 - accuracy: 0.3420 - val_loss: 1.0959 - val_accuracy: 0.3894\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 10s 417ms/step - loss: 1.1005 - accuracy: 0.3393 - val_loss: 1.0954 - val_accuracy: 0.3470\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 8s 323ms/step - loss: 1.1026 - accuracy: 0.3386 - val_loss: 1.0984 - val_accuracy: 0.3152\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 10s 433ms/step - loss: 1.0978 - accuracy: 0.3464 - val_loss: 1.0958 - val_accuracy: 0.3636\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 11s 470ms/step - loss: 1.0975 - accuracy: 0.3578 - val_loss: 1.0891 - val_accuracy: 0.3955\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 8s 349ms/step - loss: 1.0955 - accuracy: 0.3666 - val_loss: 1.0874 - val_accuracy: 0.3788\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 10s 421ms/step - loss: 1.0880 - accuracy: 0.3662 - val_loss: 1.0845 - val_accuracy: 0.3803\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 8s 340ms/step - loss: 1.0674 - accuracy: 0.4023 - val_loss: 1.0412 - val_accuracy: 0.4258\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 9s 378ms/step - loss: 1.0295 - accuracy: 0.4572 - val_loss: 0.9655 - val_accuracy: 0.4727\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 10s 428ms/step - loss: 0.9236 - accuracy: 0.5168 - val_loss: 0.8570 - val_accuracy: 0.5439\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 8s 336ms/step - loss: 0.8335 - accuracy: 0.5708 - val_loss: 0.8370 - val_accuracy: 0.5303\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 10s 412ms/step - loss: 0.7152 - accuracy: 0.6125 - val_loss: 0.8463 - val_accuracy: 0.5924\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 9s 384ms/step - loss: 0.6647 - accuracy: 0.6233 - val_loss: 0.8440 - val_accuracy: 0.5985\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 9s 356ms/step - loss: 0.6347 - accuracy: 0.6344 - val_loss: 0.7581 - val_accuracy: 0.6136\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 10s 425ms/step - loss: 0.5959 - accuracy: 0.6594 - val_loss: 0.8210 - val_accuracy: 0.6258\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 8s 322ms/step - loss: 0.5744 - accuracy: 0.6580 - val_loss: 0.8152 - val_accuracy: 0.6288\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 10s 431ms/step - loss: 0.5430 - accuracy: 0.6573 - val_loss: 0.8777 - val_accuracy: 0.6227\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 8s 342ms/step - loss: 0.5244 - accuracy: 0.6782 - val_loss: 0.9543 - val_accuracy: 0.6197\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 9s 376ms/step - loss: 0.5108 - accuracy: 0.6755 - val_loss: 0.9092 - val_accuracy: 0.6409\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 9s 385ms/step - loss: 0.5043 - accuracy: 0.6806 - val_loss: 0.9244 - val_accuracy: 0.6288\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 8s 326ms/step - loss: 0.5102 - accuracy: 0.6843 - val_loss: 0.8748 - val_accuracy: 0.6394\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 10s 426ms/step - loss: 0.4852 - accuracy: 0.6883 - val_loss: 0.9448 - val_accuracy: 0.6394\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 8s 330ms/step - loss: 0.4811 - accuracy: 0.6974 - val_loss: 0.9604 - val_accuracy: 0.6333\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 10s 439ms/step - loss: 0.4762 - accuracy: 0.7143 - val_loss: 0.8627 - val_accuracy: 0.6348\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 8s 352ms/step - loss: 0.4398 - accuracy: 0.7264 - val_loss: 0.8021 - val_accuracy: 0.6879\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 9s 380ms/step - loss: 0.4066 - accuracy: 0.8026 - val_loss: 1.2881 - val_accuracy: 0.6879\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 10s 424ms/step - loss: 0.3712 - accuracy: 0.8504 - val_loss: 0.8786 - val_accuracy: 0.8121\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 8s 333ms/step - loss: 0.3235 - accuracy: 0.8881 - val_loss: 0.9481 - val_accuracy: 0.8030\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 10s 436ms/step - loss: 0.2727 - accuracy: 0.9090 - val_loss: 1.2423 - val_accuracy: 0.8212\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 8s 344ms/step - loss: 0.2421 - accuracy: 0.9185 - val_loss: 1.2637 - val_accuracy: 0.8136\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 9s 385ms/step - loss: 0.3040 - accuracy: 0.9057 - val_loss: 0.8823 - val_accuracy: 0.7273\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 10s 435ms/step - loss: 0.3265 - accuracy: 0.8801 - val_loss: 0.9320 - val_accuracy: 0.8030\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 10s 402ms/step - loss: 0.2202 - accuracy: 0.9306 - val_loss: 1.0840 - val_accuracy: 0.8318\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 10s 425ms/step - loss: 0.1686 - accuracy: 0.9515 - val_loss: 1.2705 - val_accuracy: 0.8379\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 10s 408ms/step - loss: 0.1389 - accuracy: 0.9619 - val_loss: 1.3714 - val_accuracy: 0.8409\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 9s 355ms/step - loss: 0.1330 - accuracy: 0.9609 - val_loss: 1.3436 - val_accuracy: 0.8545\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 13s 555ms/step - loss: 0.1086 - accuracy: 0.9697 - val_loss: 1.6998 - val_accuracy: 0.8606\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 10s 432ms/step - loss: 0.0981 - accuracy: 0.9717 - val_loss: 1.6061 - val_accuracy: 0.8485\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 8s 315ms/step - loss: 0.0795 - accuracy: 0.9778 - val_loss: 1.8345 - val_accuracy: 0.8515\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 10s 435ms/step - loss: 0.0869 - accuracy: 0.9714 - val_loss: 1.8863 - val_accuracy: 0.8606\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 7s 311ms/step - loss: 0.0771 - accuracy: 0.9781 - val_loss: 1.6801 - val_accuracy: 0.8439\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 11s 474ms/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 1.8016 - val_accuracy: 0.8606\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 10s 413ms/step - loss: 0.0562 - accuracy: 0.9794 - val_loss: 1.9477 - val_accuracy: 0.8667\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 8s 352ms/step - loss: 0.0521 - accuracy: 0.9835 - val_loss: 1.8963 - val_accuracy: 0.8712\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 10s 427ms/step - loss: 0.0534 - accuracy: 0.9855 - val_loss: 1.8654 - val_accuracy: 0.8727\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 8s 350ms/step - loss: 0.0619 - accuracy: 0.9818 - val_loss: 1.6969 - val_accuracy: 0.8727\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 9s 373ms/step - loss: 0.0367 - accuracy: 0.9906 - val_loss: 2.0387 - val_accuracy: 0.8712\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 11s 447ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 2.2631 - val_accuracy: 0.8682\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 8s 320ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 2.0194 - val_accuracy: 0.8667\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 10s 420ms/step - loss: 0.0490 - accuracy: 0.9899 - val_loss: 2.1974 - val_accuracy: 0.8621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm tra độ chính xác của mô hình trên tập test\n",
        "model.load_weights(\"model_cnn_bilstm.h5\")\n",
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwLtgN5s-tjZ",
        "outputId": "11cc3ced-a3cc-4ef7-eb5b-4ffc6e2172bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 62ms/step - loss: 4.3881 - accuracy: 0.7273\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.38805627822876, 0.7272727489471436]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Neg\",\"Pos\", \"Neu\"]\n",
        "\n",
        "y_pred = model.predict(X_val)  # Dự đoán trên tập validation\n",
        "# y_pred = model.predict(X_test)  # Dự đoán trên tập test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg4pHTTZ-vOR",
        "outputId": "aea633cd-312f-43e8-b39f-73ff77126c8e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 3s 50ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred = [labels[np.argmax(pred)] for pred in y_pred]\n",
        "y_true = [labels[np.argmax(true)] for true in y_val]  # Nhãn thực tế trên tập validation\n",
        "# y_true = [labels[np.argmax(true)] for true in y_test]  # Nhãn thực tế trên tập test"
      ],
      "metadata": {
        "id": "PowxIy02-wgT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "report = classification_report(y_true, y_pred, zero_division=1)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoUeaVnA-x7e",
        "outputId": "ca3316ac-781a-4cb9-a68e-2b1cb3ecdeea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Neg       0.83      0.89      0.86       227\n",
            "         Neu       0.84      0.82      0.83       196\n",
            "         Pos       0.92      0.86      0.89       237\n",
            "\n",
            "    accuracy                           0.86       660\n",
            "   macro avg       0.86      0.86      0.86       660\n",
            "weighted avg       0.86      0.86      0.86       660\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_raw_input(raw_input, tokenizer):\n",
        "  input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))\n",
        "  input_text_pre = \" \".join(input_text_pre)\n",
        "  input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
        "  print(\"Text preprocessed: \", input_text_pre_accent)\n",
        "  tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])\n",
        "  vec_data = pad_sequences(tokenized_data_text, padding='post', maxlen=120)\n",
        "  return vec_data\n",
        "\n",
        "def inference_model(input_feature, model):\n",
        "  output = model(input_feature).numpy()[0]\n",
        "  result = output.argmax()\n",
        "  conf = float(output.max())\n",
        "  label_dict = {'Tiêu cực':0, 'Tích cực':1, 'Trung lập':2}\n",
        "  label = list(label_dict.keys())\n",
        "  return label[int(result)], conf\n",
        "\n",
        "def prediction(raw_input, tokenizer, model):\n",
        "  input_model = preprocess_raw_input(raw_input, tokenizer_data)\n",
        "  result, conf = inference_model(input_model, model)\n",
        "\n",
        "  return result, conf\n",
        "\n",
        "my_model = generate_model()\n",
        "my_model = load_model('model_cnn_bilstm.h5')\n",
        "\n",
        "with open(r\"tokenizer_data.pkl\", \"rb\") as input_file:\n",
        "  my_tokenizer = pickle.load(input_file)\n",
        "\n",
        "print(prediction(\"Ứng dụng bình thường\", my_tokenizer, my_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzKobwuN-zTc",
        "outputId": "b246016c-ed73-46c1-9df4-7e9017c2da1a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessed:  ứng_dụng bình_thường\n",
            "('Trung lập', 0.9898321628570557)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vòng lặp vô hạn để kiểm thử mô hình phân loại dựa vào đầu vào từ\n",
        "# người dùng qua dòng lệnh. Người dùng sẽ nhập các đoạn văn bản để mô hình\n",
        "# dự đoán lớp (sentiment) tương ứng cho mỗi đoạn văn bản đó.\n",
        "# Người dùng có thể nhập \"end\" để kết thúc vòng lặp và thoát khỏi chương trình\n",
        "while(True):\n",
        "  text = input()\n",
        "  if text == \"end\":\n",
        "    break\n",
        "  else:\n",
        "    print(prediction(text, my_tokenizer, my_model)[0] + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am2fneS0-1GC",
        "outputId": "1ce0e0be-08ad-4d92-e86a-e4b747e0dd61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ứng dụng dùng tuyệt vời \n",
            "Text preprocessed:  ứng_dụng dùng tuyệt_vời\n",
            "Tích cực\n",
            "\n",
            "không nên mua vì nó dùng không bao giờ hư\n",
            "Text preprocessed:  không nên mua vì nó dùng không bao_giờ hư\n",
            "Tiêu cực\n",
            "\n",
            "hay quá \n",
            "Text preprocessed:  hay quá\n",
            "Tiêu cực\n",
            "\n",
            "Dùng ổn nha\n",
            "Text preprocessed:  dùng ổn nha\n",
            "Tích cực\n",
            "\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbMhUiIRYnNA",
        "outputId": "b053039f-9ed4-4c9e-a4c9-58dd8cc5ac73"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "from pyvi import ViTokenizer\n",
        "import pickle\n",
        "\n",
        "def preprocess_raw_input(raw_input, tokenizer):\n",
        "    input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))\n",
        "    input_text_pre = \" \".join(input_text_pre)\n",
        "    input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
        "    tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])\n",
        "    vec_data = pad_sequences(tokenized_data_text, padding='post', maxlen=120)\n",
        "    return vec_data\n",
        "\n",
        "def inference_model(input_feature, model):\n",
        "    output = model(input_feature).numpy()[0]\n",
        "    result = output.argmax()\n",
        "    conf = float(output.max())\n",
        "    label_dict = {'Tiêu cực': 0, 'Tích cực': 1, 'Trung lập': 2}\n",
        "    label = list(label_dict.keys())\n",
        "    return label[int(result)], conf\n",
        "\n",
        "def prediction(raw_input, tokenizer, model):\n",
        "    input_model = preprocess_raw_input(raw_input, tokenizer)\n",
        "    result, conf = inference_model(input_model, model)\n",
        "    return result, conf\n",
        "\n",
        "# Tải model và tokenizer\n",
        "@st.cache_resource\n",
        "def load_model_and_tokenizer():\n",
        "    model = load_model('model_cnn_bilstm.h5')\n",
        "    with open(\"tokenizer_data.pkl\", \"rb\") as input_file:\n",
        "        tokenizer = pickle.load(input_file)\n",
        "    return model, tokenizer\n",
        "\n",
        "# Tải model và tokenizer\n",
        "my_model, my_tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "# Giao diện Streamlit\n",
        "st.title('Dự đoán Cảm xúc Văn bản Tiếng Việt')\n",
        "st.write('Nhập văn bản của bạn vào ô dưới đây và nhận kết quả dự đoán cảm xúc.')\n",
        "\n",
        "user_input = st.text_area('Nhập văn bản tại đây:')\n",
        "\n",
        "if st.button('Dự đoán'):\n",
        "    if user_input:\n",
        "        result, conf = prediction(user_input, my_tokenizer, my_model)\n",
        "        st.write(f'Kết quả: {result}')\n",
        "        st.write(f'Độ tin cậy: {conf:.2f}')\n",
        "    else:\n",
        "        st.write('Vui lòng nhập văn bản để dự đoán.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwbPcMbj1sbC",
        "outputId": "791023b8-b1e2-4d16-e46a-fbd5537990d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import tensorflow as tf\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from keras.models import Model\n",
        "from pyvi import ViTokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "def preprocess_raw_input(raw_input, tokenizer):\n",
        "  input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))\n",
        "  input_text_pre = \" \".join(input_text_pre)\n",
        "  input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
        "  print(\"Text preprocessed: \", input_text_pre_accent)\n",
        "  tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])\n",
        "  vec_data = pad_sequences(tokenized_data_text, padding='post', maxlen=120)\n",
        "  return vec_data\n",
        "\n",
        "# def inference_model(input_feature, model):\n",
        "#   output = model(input_feature).numpy()[0]\n",
        "#   result = output.argmax()\n",
        "#   conf = float(output.max())\n",
        "#   label_dict = {'Tiêu cực':0, 'Tích cực':1, 'Trung lập':2}\n",
        "#   label = list(label_dict.keys())\n",
        "#   return label[int(result)], conf\n",
        "\n",
        "# def prediction(raw_input, tokenizer, model):\n",
        "#   input_model = preprocess_raw_input(raw_input, tokenizer_data)\n",
        "#   result, conf = inference_model(input_model, model)\n",
        "\n",
        "#   return result, conf\n",
        "st.write(\"\"\"\n",
        "# Mô hình dự đoán sự hài lòng của khách hàng\n",
        "\n",
        "Mô hình dự đoán lương dựa sự hài lòng của khách hàng hàng không\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "with open(r\"tokenizer_data.pkl\", \"rb\") as input_file:\n",
        "  my_tokenizer = pickle.load(input_file)\n",
        "\n",
        "user_input = st.text_input('Nhập văn bản:')\n",
        "st.write(user_input)\n",
        "user_input_final = preprocess_raw_input(user_input, my_tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "my_model = load_model('model_cnn_bilstm.h5')\n",
        "\n",
        "\n",
        "if user_input_final:\n",
        "    pred = my_model.predict(user_input_final)[0]\n",
        "\n",
        "    # Display prediction\n",
        "    if pred == 'Tích cực':\n",
        "        st.write('## Sự hài lòng của khách hàng: Tích cực')\n",
        "    elif pred == 'Tiêu cực':\n",
        "        st.write('## Sự hài lòng của khách hàng: Tiêu cực')\n",
        "    else:\n",
        "        st.write('## Sự hài lòng của khách hàng: Trung lập')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-aCaODFc51G",
        "outputId": "3a9497b8-49cb-4d71-e40d-0ecdc13a63cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PRWGvHbD8d",
        "outputId": "24b711e6-d220-4c0c-8947-0f3eaed0fff5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 0.886s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33m   ╭────────────────────────────────────────────────────────────────╮\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m      New \u001b[31mmajor\u001b[39m version of npm available! \u001b[31m6.14.8\u001b[39m → \u001b[32m10.8.1\u001b[39m       \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m   \u001b[33mChangelog:\u001b[39m \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.8.1\u001b[39m   \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m               Run \u001b[32mnpm install -g npm\u001b[39m to update!                \u001b[33m│\u001b[39m\n",
            "   \u001b[33m│\u001b[39m                                                                \u001b[33m│\u001b[39m\n",
            "\u001b[33m   ╰────────────────────────────────────────────────────────────────╯\u001b[39m\n",
            "\u001b[33m\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mA08tjdZ7Ki",
        "outputId": "e5d78424-cfdc-4ec3-c611-bd551c9906cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.12.231\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.123s\n",
            "your url is: https://major-hotels-cheer.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCr6NXvSeWyh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}